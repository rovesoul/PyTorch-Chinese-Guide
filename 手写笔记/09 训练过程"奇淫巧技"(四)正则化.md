# 09 训练过程"奇淫巧技"(四)正则化

$$f = loss + \lambda \sum peparams||p||^2 $$ 

loss --普通loss
𝜆 --权重衰减因子
∑ --里边是权重L2惩罚

在优化目标时候,一般使用L2 正则化 ，更新参数的公式就是

$$
p_j \rightarrow p_j - \eta (\frac{\partial loss}{\partial p_j} + 2 \lambda p_j) = p_j - \eta \frac{\partial loss}{\partial p_j} - 2 \eta \lambda p_j 
$$

如果想在随机梯度下降法中使用正则项，或者说权重衰减，`torch.optim.SGD(net.parameters(), lr=0.1, weight_decay=1e-4)` 就可以了，这个 `weight_decay` 系数就是上面公式中的 $\lambda$，非常方便
```python
optimizer = torch.optim.SGD(net.parameters(), lr=0.01, weight_decay=1e-4) 
# weight_decay就是增加正则项
```

公式可能出不来,不过不重要
