# 06 训练过程"奇淫巧技"(一)数据增强
1. 数据增强
2. 学习率衰减
3. Dropout
4. 正则化

## 数据增强
常用的数据增强方法
常用的数据增强方法如下：
1. 对图片进行一定比例缩放
2. 对图片进行随机位置的截取
3. 对图片进行随机的水平和竖直翻转
4. 对图片进行随机角度的旋转
5. 对图片进行亮度、对比度和颜色的随机变化

这些方法 pytorch 都已经为我们内置在了 [torchvision(点击看文档)](https://pytorch.org/docs/0.3.0/torchvision/transforms.html) 里面，我们在安装 pytorch 的时候也安装了 torchvision
### 图像缩放
> 一般的卷积神经网络输入要求大小尺寸相同,因此在一开始就要缩放好

下边代码展示一张图片的大小转换
```python
from PIL import Image
from torchvision import transforms as tfs

# 读入一张图片
im = Image.open('./cat.png')

# 看一下大小
print('before scale, shape: {}'.format(im.size))
# 转换  # 括号里(高,宽)
new_im = tfs.Resize((100, 200))(im)
# 看转换后大小
print('after scale, shape: {}'.format(new_im.size))
new_im
```
### 随机截取
下边代码展示随机截取100*100 面积的区域
```python
from PIL import Image
from torchvision import transforms as tfs

# 读入一张图片
im = Image.open('./cat.png')
# 随机裁剪出 100 x 100 的区域
random_im1 = tfs.RandomCrop(100)(im)
random_im1  #这句在notebook中为了显示一下图片
# 随机裁剪出 150 x 100 的区域
random_im2 = tfs.RandomCrop((150, 100))(im)
random_im2  #这句在notebook中为了显示一下图片
# 中心裁剪出 100 x 100 的区域
center_im = tfs.CenterCrop(100)(im)
center_im  #这句在notebook中为了显示一下图片
```
### 随机翻转
如果我们将它翻转一下，它仍然是一张猫，但是图片就有了更多的多样性，所以随机翻转也是一种非常有效的手段。在 torchvision 中，随机翻转使用的是
```python
# 随机水平翻转
h_filp = tfs.RandomHorizontalFlip()(im)
h_filp #这句在notebook中为了显示一下图片
# 随机竖直翻转
v_flip = tfs.RandomVerticalFlip()(im)
v_flip
```
### 随机角度旋转
一些角度的旋转仍然是非常有用的数据增强方式，在 torchvision 中，使用 `torchvision.transforms.RandomRotation() `来实现，其中第一个参数就是随机旋转的角度，比如填入 10，那么每次图片就会在 -10 ~ 10 度之间随机旋转
```python
rot_im = tfs.RandomRotation(45)(im)
rot_im
```
### 亮度、对比度和颜色的变化
除了形状变化外，颜色变化又是另外一种增强方式，其中可以设置亮度变化，对比度变化和颜色变化等，在 torchvision 中主要使用 torchvision.transforms.ColorJitter() 来实现的，第一个参数就是亮度的比例，第二个是对比度，第三个是饱和度，第四个是颜色
```python
# 亮度
bright_im = tfs.ColorJitter(brightness=1)(im) # 随机从 0 ~ 2 之间亮度变化，1 表示原图
bright_im

# 对比度
contrast_im = tfs.ColorJitter(contrast=1)(im) # 随机从 0 ~ 2 之间对比度变化，1 表示原图
contrast_im

# 颜色
color_im = tfs.ColorJitter(hue=0.5)(im) # 随机从 -0.5 ~ 0.5 之间对颜色变化
color_im
```
### 联合使用
上面我们讲了这么图片增强的方法，其实这些方法都不是孤立起来用的，可以联合起来用，比如先做随机翻转，然后随机截取，再做对比度增强等等，torchvision 里面有个非常方便的函数能够将这些变化合起来，就是 torchvision.transforms.Compose()，下面我们举个例子
```python
from PIL import Image
from torchvision import transforms as tfs

im = Image.open('/Users/donghuibiao/Desktop/网课学习/DeepLearning-self/OpenCV/putText.jpg')


im_aug = tfs.Compose([
    tfs.Resize(120),
    tfs.RandomHorizontalFlip(),
    tfs.RandomCrop(96),
    tfs.ColorJitter(brightness=0.5, contrast=0.5, hue=0.5)
])

import matplotlib.pyplot as plt

nrows = 3
ncols = 3
figsize = (8, 8)
_, figs = plt.subplots(nrows, ncols, figsize=figsize)
for i in range(nrows):
    for j in range(ncols):
        figs[i][j].imshow(im_aug(im))
        figs[i][j].axes.get_xaxis().set_visible(False)
        figs[i][j].axes.get_yaxis().set_visible(False)
plt.show()
```

使用数据集时,数据增强可以这么用
```python
# 使用数据增强,先定义一个增强函数
def train_tf(x):
    im_aug = tfs.Compose([
        tfs.Resize(120),
        tfs.RandomHorizontalFlip(),
        tfs.RandomCrop(96),
        tfs.ColorJitter(brightness=0.5, contrast=0.5, hue=0.5),
        tfs.ToTensor(),
        tfs.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
    ])
    x = im_aug(x)
    return x

# 测试集也增强一下
def test_tf(x):
    im_aug = tfs.Compose([
        tfs.Resize(96),
        tfs.ToTensor(),
        tfs.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
    ])
    x = im_aug(x)
    return x

# 训练集,测试集可以这么定义
train_set = CIFAR10('./data', train=True, transform=train_tf)
train_data = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)
test_set = CIFAR10('./data', train=False, transform=test_tf)
test_data = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False)

```

结论是:对于训练集，不做数据增强跑 10 次，准确率已经到了 95%，而使用了数据增强，跑 10 次准确率只有 75%，说明数据增强之后变得更难了。

而对于测试集，使用数据增强进行训练的时候，准确率会比不使用更高，因为数据增强提高了模型应对于更多的不同数据集的泛化能力，所以有更好的效果。

董汇标,记录于2019/10/28
